{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73903857-0b52-430e-b6a0-185d5d8713db",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f41558-e3d6-4708-ae24-89ede93d39f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import yfinance as yf\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta\n",
    "from time import sleep\n",
    "from random import random\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "from time import mktime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271487f1-edd9-4830-b242-675b38f45c4d",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b9a24a-59e0-4ef8-b541-ac9049575bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getTicker(searchterm):\n",
    "    head = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "    #searchterm = input()\n",
    "    queryurl = 'https://www.google.com/search?q='+searchterm+'+stock'\n",
    "    page = requests.get(queryurl,headers=head)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    res = soup.find('div', class_=\"iAIpCb PZPZlf\")\n",
    "    if res != None:\n",
    "        return res.text.split()[1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de65912-92f9-4c27-8715-8976345dd344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wsj_extractor(html):\n",
    "    headlines = list()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    sectionlist = soup.find_all('div', class_='WSJTheme--overflow-hidden--qJmlzHgO')\n",
    "    for section in sectionlist:\n",
    "        art = section.find('span', class_='WSJTheme--headlineText--He1ANr9C')\n",
    "        headlines.append(art.text)\n",
    "    return headlines\n",
    "\n",
    "def tbs_extractor(html):\n",
    "    headlines = list()\n",
    "    date_exception = re.compile('\\d\\d-\\d\\d-\\d\\d\\d\\d')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    sectionlist = soup.find_all('h4', class_='card-title')\n",
    "    for section in sectionlist:\n",
    "        art = section.find('a').text\n",
    "        if not date_exception.match(art):\n",
    "            headlines.append(art)\n",
    "    return headlines\n",
    "\n",
    "def nyt_extractor(html):\n",
    "    headlines = list()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    sectionlist = soup.find_all('h2', class_='css-ds6ff4 e1b0gigc0')\n",
    "    for section in sectionlist:\n",
    "        headlines.append(section.text)\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e94fd7-a0c6-401a-bb82-4d6a14bc6670",
   "metadata": {},
   "source": [
    "# Parameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5189eaff-0941-4699-a091-e12047b9b898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter stock:  amazon\n"
     ]
    }
   ],
   "source": [
    "head = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "today = date.today()\n",
    "oneday = timedelta(days=1)\n",
    "print(today)\n",
    "\n",
    "sources = ['wsj','tbs','nyt']\n",
    "\n",
    "urls =    {'wsj': lambda day: 'https://www.wsj.com/news/archive/'+day.strftime('%Y/%m/%d'),\n",
    "           'tbs': lambda day: 'https://www.tbsnews.net/archive/'+day.strftime('%Y/%m/%d'),\n",
    "           'nyt': lambda day: 'https://www.nytimes.com/issue/todaysheadlines/'+day.strftime('%Y/%m/%d')+'/todays-headlines'}\n",
    "extractors = {'wsj': wsj_extractor,\n",
    "              'tbs': tbs_extractor,\n",
    "              'nyt': nyt_extractor}\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "num_years = 3\n",
    "searchterm = input('Enter stock: ').casefold()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f311203-d900-457b-ab4e-61856080e2f8",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb28fcd-9233-4a77-b441-4fd238c6412a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping...:   0%|                                                                            | 0/1095 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed at: 2023-07-03 for nyt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping...: 100%|█████████████████████████████████████████████████████████████████| 1095/1095 [01:04<00:00, 17.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for src in sources:\n",
    "    if not exists(src):\n",
    "        mkdir(src)\n",
    "        \n",
    "#search_score_list = list()\n",
    "#score_df = pd.DataFrame(columns = ['Score','Date']).set_index('Date')\n",
    "        \n",
    "if exists('stock_sent_data.csv'):\n",
    "    news_df = pd.read_csv('stock_sent_data.csv')\n",
    "    news_df.date = pd.to_datetime(news_df.date)\n",
    "else:\n",
    "    news_df = pd.DataFrame(columns = ['title','date','source'])\n",
    "    \n",
    "day = today+oneday\n",
    "#last_idx = len(news_df.index)\n",
    "new_arts = list()\n",
    "for i in tqdm(range(int(num_years*365)), desc = 'Scraping...'):\n",
    "    day = day - oneday\n",
    "    pday = pd.to_datetime(day)\n",
    "    wait = False\n",
    "    for src in sources:\n",
    "        if src not in news_df.loc[(news_df['date'] == pday)]['source'].values:\n",
    "            fileurl = src+'/'+str(day)+'.html'\n",
    "            if not exists(fileurl):\n",
    "                url = urls[src](day)\n",
    "                html = requests.get(url, headers = head)\n",
    "                try:\n",
    "                    html.raise_for_status()\n",
    "                    with open(fileurl, 'wb+') as f:\n",
    "                        f.write(html.content)\n",
    "                    #sleep(0.5+random())\n",
    "                    wait = True\n",
    "                except:\n",
    "                    print('failed at: '+str(day)+' for '+src)\n",
    "                    continue\n",
    "            with open(fileurl, 'rb') as f:\n",
    "                html = f.read()\n",
    "            for headline in extractors[src](html) or []:\n",
    "                #last_idx+=1\n",
    "                #news_df.loc[last_idx] = [headline, pday, src]\n",
    "                new_arts.append([headline, pday, src])\n",
    "\n",
    "    if wait:\n",
    "        sleep(random())\n",
    "news_df = pd.concat([news_df, pd.DataFrame(new_arts, columns = ['title','date','source'])])        \n",
    "news_df = news_df.sort_values('date').reset_index(drop=True)\n",
    "news_df.to_csv('stock_sent_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33990db1-1491-487b-ad35-b38fec3a9000",
   "metadata": {},
   "source": [
    "# Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcba28e2-01af-4477-abd4-19b64f62bdb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring...: 100%|██████████████████████████████████████████████████████████████████| 1095/1095 [00:22<00:00, 49.40it/s]\n"
     ]
    }
   ],
   "source": [
    "day = today+oneday\n",
    "news_df = pd.read_csv('stock_sent_data.csv')\n",
    "search_score_list = list()\n",
    "score_df = pd.DataFrame(columns = ['Score','Date']).set_index('Date')\n",
    "for i in tqdm(range(int(num_years*365)), desc='Scoring...'):    \n",
    "    day = day - oneday\n",
    "    pday = pd.to_datetime(day)\n",
    "    day_df = news_df.loc[(news_df['date'] == pday)]['title']\n",
    "    score = 0\n",
    "    for article in day_df:\n",
    "        if not article:\n",
    "            continue\n",
    "        num_matches = 0\n",
    "        if searchterm in article.casefold():\n",
    "            score+= analyzer.polarity_scores(article)['compound']\n",
    "            num_matches+= 1\n",
    "        if num_matches != 0:\n",
    "            score/=num_matches\n",
    "    score_df.loc[pday] = [score]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed26e8e-9518-4185-b3d3-a4080d7f531b",
   "metadata": {},
   "source": [
    "# Stock Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d44d52-e8f2-47a3-95ef-f613d40c4892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock = yf.Ticker(getTicker(searchterm))\n",
    "stock_df = stock.history(period=str(num_years)+'y')\n",
    "\n",
    "stock_df = stock_df.loc[:,['Open', 'High', 'Low', 'Close']]\n",
    "stock_df.index = stock_df.index.tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc32fb-f5bf-4405-9bfd-f35ff0fd8d4f",
   "metadata": {},
   "source": [
    "# ML Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5519858-84e1-4355-a608-55035c869c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stockpipe(stock_df, score_df, given_size=None):\n",
    "    Scaler = StandardScaler()\n",
    "    scaled_df = Scaler.fit_transform(stock_df)\n",
    "\n",
    "    interval = 30\n",
    "\n",
    "    stock_df = pd.DataFrame(scaled_df, columns = stock_df.columns, index=stock_df.index.tz_localize(None))\n",
    "    #print(\"Scaled Dataframe: \\n\",df)\n",
    "    stock_columns = stock_df.columns\n",
    "    date_index = stock_df.index\n",
    "\n",
    "    df = stock_df.join(score_df['Score']).fillna(0)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    start_idx = 0\n",
    "    for stop_idx in range(interval, len(df)-1):\n",
    "        sequences.append(df.loc[start_idx:stop_idx])\n",
    "        labels.append(df.loc[stop_idx+1])\n",
    "        start_idx += 1\n",
    "    #return np.array(sequences), np.array(labels)\n",
    "\n",
    "    sequences = np.array([[[float(x) for x in list ]for list in blist] for blist in np.array(sequences)])\n",
    "    labels = np.array([[float(y) for y in blist ] for blist in np.array(labels)])\n",
    "\n",
    "    # print(len(sequences))\n",
    "    # print(len(labels))\n",
    "    # for i in range(len(sequences)):\n",
    "    #   print(sequences[i], \":   \", labels[i])\n",
    "\n",
    "    if given_size != None:\n",
    "        train_size = int(given_size * len(sequences))\n",
    "        trainX = sequences[:train_size]\n",
    "        trainY = labels[:train_size]\n",
    "        testX = sequences[train_size:]\n",
    "        testY = labels[train_size:]\n",
    "\n",
    "        trainY = np.delete(trainY, -1, 1)\n",
    "        testY = np.delete(testY, -1, 1)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=50, return_sequences=True, input_shape = (trainX.shape[1], trainX.shape[2])))\n",
    "        model.add(Dropout(0.1)) \n",
    "        model.add(LSTM(units=50))\n",
    "        model.add(Dense(trainX.shape[2]-1))\n",
    "\n",
    "        # model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.summary()\n",
    "        model.fit(trainX, trainY, epochs=100, batch_size=None) #epochs ought to be 20+ I guess\n",
    "\n",
    "        #Prediction\n",
    "        predY = model.predict(testX)\n",
    "     \n",
    "        series_plus_one = testX[-1]\n",
    "        series_plus_one = np.delete(series_plus_one, 0, 0)\n",
    "        series_plus_one = np.vstack([series_plus_one, np.hstack([predY[-1],np.array([0])])])\n",
    "        plus_one_Y = model.predict(np.array([series_plus_one]))\n",
    "        plus_one_Y = Scaler.inverse_transform(plus_one_Y)\n",
    "\n",
    "        next_day_df = pd.DataFrame(plus_one_Y, columns = stock_columns)\n",
    "        print('\\nNext day\\'s predicted values: \\n', next_day_df)\n",
    "    \n",
    "        predY = Scaler.inverse_transform(predY)\n",
    "        rmse = np.sqrt(np.mean((predY - Scaler.inverse_transform(testY))**2))\n",
    "        print('\\nRoot Mean Squared Error (RMSE):', rmse,\"\\n\\n\")\n",
    "\n",
    "        pred_df = pd.DataFrame(predY, columns = stock_columns, index = date_index[-len(predY):])\n",
    "        #print(\"Length of pred_df\",len(pred_df))\n",
    "        #print(pred_df)\n",
    "\n",
    "        test_arr = Scaler.inverse_transform(testY)\n",
    "        testplot_df = pd.DataFrame(test_arr, columns = stock_columns, index = date_index[-len(pred_df):])\n",
    "        #print(\"Length of testplot_df\",len(testplot_df))\n",
    "        #print(testplot_df)\n",
    "\n",
    "        plotting_column = 'High'\n",
    "        #sns.lineplot(x = date_index[(len(trainX)+31):], y = pred_df[plotting_column], color='blue')\n",
    "        #sns.lineplot(x = date_index[(len(trainX)+31):], y = testplot_df[plotting_column], color='orange')\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.lineplot(x = pred_df.index, y = pred_df[plotting_column], color='cyan')\n",
    "        sns.lineplot(x = testplot_df.index, y = testplot_df[plotting_column], color='orange')\n",
    "        plt.xticks(rotation=50)\n",
    "        plt.grid()\n",
    "\n",
    "        #df = Scaler.inverse_transform(df)\n",
    "        #df = pd.DataFrame(df, columns = stock_columns, index=date_index)\n",
    "        return df, date_index, testplot_df, pred_df\n",
    "\n",
    "    return df, date_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5fbde-e0b6-46f7-828a-70ce477135a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eg_df, date_index, pred_df, testplot_df = stockpipe(stock_df, score_df,given_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7750282d-944f-4452-8412-399b9bcb8bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for daily High: 0.96722\n",
      "R2 score for Opening price: 0.97988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "merged_df = pd.merge(pred_df, testplot_df, on=pred_df.index)\n",
    "\n",
    "#mape_1 = mean_absolute_percentage_error(merged_df['High_x'], merged_df['High_y'])\n",
    "#mape_2 = mean_absolute_percentage_error(merged_df['Open_x'], merged_df['Open_y'])\n",
    "r2_1 = r2_score(merged_df['High_x'], merged_df['High_y'])\n",
    "r2_2 = r2_score(merged_df['Open_x'], merged_df['Open_y'])\n",
    "\n",
    "#print(f\"MAPE for daily High: {mape_1:.2f}\")\n",
    "#print(f\"MAPE for Opening price: {mape_2:.2f}\")\n",
    "print(f\"R2 score for daily High: {r2_1:.5f}\")\n",
    "print(f\"R2 score for Opening price: {r2_2:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ca738-15fe-4950-a058-108c8798a28d",
   "metadata": {},
   "source": [
    "# Alternative Scraper-Analyzer:\n",
    "No long term storage requirements but consistently needs more time\n",
    "> Turnaround time can be improved at risk of being IP banned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667c4c5-f32d-4c1d-903c-1a543d4621de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "day = today+oneday\n",
    "search_score_list = list()\n",
    "score_df = pd.DataFrame(columns = ['Score','Date']).set_index('Date')\n",
    "for i in tqdm(range(int(num_years*365)), desc='Scoring...'):    \n",
    "    day = day - oneday\n",
    "    pday = pd.to_datetime(day)\n",
    "    url = 'https://timesofindia.indiatimes.com/topic/'+searchterm+'/news?dateFilter='+str(mktime(day.timetuple())*1000)+','+str(mktime(day.timetuple())*1000-86400)\n",
    "    html = requests.get(url, headers = head)\n",
    "    headlines = list()\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    title_list = soup.find_all('div', class_='fHv_i o58kM')\n",
    "    #blurb_list = soup.find_all('p', class_='oxXSK o58kM')\n",
    "    for title in title_list:\n",
    "        art = title.find('span')\n",
    "        headlines.append(art.text)\n",
    "    #day_df = news_df.loc[(news_df['date'] == pday)]['title']\n",
    "    score = 0\n",
    "    for article in headlines:\n",
    "        if not article:\n",
    "            continue\n",
    "        num_matches = 0\n",
    "        if searchterm in article.casefold():\n",
    "            score+= analyzer.polarity_scores(article)['compound']\n",
    "            num_matches+= 1\n",
    "        if num_matches != 0:\n",
    "            score/=num_matches\n",
    "    score_df.loc[pday] = [score]\n",
    "    sleep(random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30e699-2f6f-4300-91b0-6ed2f8c5889c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
